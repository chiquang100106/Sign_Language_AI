import cv2
import mediapipe as mp
import numpy as np
import os
import math


# --- C·∫§U H√åNH X·ª¨ L√ù H√ÄNG LO·∫†T ---
CLASS_NAME = "Y"  # T√™n nh√£n (Ch·ªØ c√°i) ƒëang x·ª≠ l√Ω
INPUT_FOLDER = f"data/raw_videos/{CLASS_NAME}"
OUTPUT_FOLDER = f"data/input_images/{CLASS_NAME}"  # Folder l∆∞u ·∫£nh ƒë·∫ßu ra

# --- C·∫§U H√åNH QUAN TR·ªåNG ---
CLASS_NAME = "H"  # T√™n folder con mu·ªën l∆∞u
INPUT_FOLDER = f"D:\\sign_language\\data\\raw_video\\{CLASS_NAME}"
OUTPUT_FOLDER = f"D:\\sign_language\\data\\input_images\\{CLASS_NAME}"


# --- C·∫§U H√åNH CHO EFFICIENTNET / MOBILENET ---
IMG_SIZE = 224  # Size ƒë·∫ßu v√†o cho ·∫£nh
TARGET_COUNT_PER_VIDEO = 65  # M·ª•c ti√™u: Mu·ªën l·∫•y kho·∫£ng 60-65 ·∫£nh m·ªói video


# T·∫°o th∆∞ m·ª•c ƒë·∫ßu ra
if not os.path.exists(OUTPUT_FOLDER):
    os.makedirs(OUTPUT_FOLDER)

# --- KH·ªûI T·∫†O MEDIAPIPE ---
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)

# C·∫•u h√¨nh Bounding Box
DESIRED_ASPECT_RATIO = 1.0
PADDING = 40


def process_frame(frame):
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    return hands.process(rgb_frame)


def calculate_bounding_box(hand_landmarks, frame_shape):
    h, w, _ = frame_shape
    x_min, y_min = w, h
    x_max, y_max = 0, 0
    for lm in hand_landmarks.landmark:
        x, y = int(lm.x * w), int(lm.y * h)
        x_min = min(x, x_min)
        y_min = min(y, y_min)
        x_max = max(x, x_max)
        y_max = max(y, y_max)
    x_min = max(0, x_min - PADDING)
    y_min = max(0, y_min - PADDING)
    x_max = min(w, x_max + PADDING)
    y_max = min(h, y_max + PADDING)
    return x_min, y_min, x_max, y_max


def enforce_aspect_ratio(x_min, y_min, x_max, y_max, frame_shape, desired_aspect_ratio):
    h, w, _ = frame_shape
    box_width = x_max - x_min
    box_height = y_max - y_min
    current_aspect_ratio = box_height / box_width
    if current_aspect_ratio < desired_aspect_ratio:
        new_height = int(box_width * desired_aspect_ratio)
        y_center = (y_min + y_max) // 2
        y_min = max(0, y_center - new_height // 2)
        y_max = min(h, y_center + new_height // 2)
    elif current_aspect_ratio > desired_aspect_ratio:
        new_width = int(box_height / desired_aspect_ratio)
        x_center = (x_min + x_max) // 2
        x_min = max(0, x_center - new_width // 2)
        x_max = min(w, x_center + new_width // 2)
    return x_min, y_min, x_max, y_max


def crop_hand(frame, x_min, y_min, x_max, y_max):
    return frame[y_min:y_max, x_min:x_max]


def main():
    if not os.path.exists(INPUT_FOLDER):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {INPUT_FOLDER}")
        return

    video_files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(('.mp4', '.avi', '.mov', '.MOV'))]
    print(f"üìÇ T√¨m th·∫•y {len(video_files)} video. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω th√¥ng minh...")

    total_images_all_videos = 0

    for video_name in video_files:
        video_path = os.path.join(INPUT_FOLDER, video_name)
        cap = cv2.VideoCapture(video_path)

        # --- B∆Ø·ªöC 1: T√çNH TO√ÅN B∆Ø·ªöC NH·∫¢Y (DYNAMIC STEP) ---
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if total_frames == 0:
            print(f"‚ö†Ô∏è L·ªói ƒë·ªçc video {video_name}, b·ªè qua.")
            continue

        # T√≠nh to√°n: C·∫ßn nh·∫£y bao nhi√™u frame ƒë·ªÉ l·∫•y ƒë·ªß s·ªë l∆∞·ª£ng mong mu·ªën?
        # V√≠ d·ª•: 300 frame / 60 ·∫£nh = 5 (C·ª© 5 frame l·∫•y 1)
        skip_step = max(1, int(total_frames / TARGET_COUNT_PER_VIDEO))

        print(f"‚ñ∂Ô∏è X·ª≠ l√Ω: {video_name}")
        print(f"   ‚ÑπÔ∏è T·ªïng frame: {total_frames} | M·ª•c ti√™u: ~{TARGET_COUNT_PER_VIDEO} ·∫£nh | B∆∞·ªõc nh·∫£y: {skip_step}")

        frame_idx = 0
        saved_count = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break

            # --- B∆Ø·ªöC 2: KI·ªÇM TRA ƒêI·ªÄU KI·ªÜN L·∫§Y ·∫¢NH ---
            # Ch·ªâ x·ª≠ l√Ω n·∫øu frame hi·ªán t·∫°i n·∫±m trong b∆∞·ªõc nh·∫£y
            if frame_idx % skip_step == 0:

                # --- X·ª≠ l√Ω Detect & Crop ---
                # frame = cv2.flip(frame, 1) # M·ªü l·∫°i n·∫øu c·∫ßn l·∫≠t ·∫£nh

                result = process_frame(frame)

                if result.multi_hand_landmarks:
                    for hand_landmarks, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):

                        if True:
                            x_min, y_min, x_max, y_max = calculate_bounding_box(hand_landmarks, frame.shape)
                            x_min, y_min, x_max, y_max = enforce_aspect_ratio(x_min, y_min, x_max, y_max, frame.shape,
                                                                              DESIRED_ASPECT_RATIO)

                            hand_crop = crop_hand(frame, x_min, y_min, x_max, y_max)

                            if hand_crop.size != 0:
                                try:
                                    # Resize v·ªÅ 224x224 cho EfficientNet/MobileNet
                                    hand_crop_resized = cv2.resize(hand_crop, (IMG_SIZE, IMG_SIZE))

                                    # ƒê·∫∑t t√™n file
                                    filename = f"{os.path.splitext(video_name)[0]}_fr{frame_idx}.jpg"
                                    save_path = os.path.join(OUTPUT_FOLDER, filename)

                                    cv2.imwrite(save_path, hand_crop_resized)
                                    saved_count += 1

                                    # In ra m·ªói 10 ·∫£nh cho ƒë·ª° spam terminal
                                    if saved_count % 10 == 0:
                                        print(f"      ---> ƒê√£ l∆∞u {saved_count} ·∫£nh...")
                                except Exception as e:
                                    print(f"‚ö†Ô∏è L·ªói save frame {frame_idx}: {e}")

                            # Break ƒë·ªÉ ch·ªâ l·∫•y 1 tay ∆∞u ti√™n trong 1 frame (tr√°nh tr√πng l·∫∑p n·∫øu c√≥ 2 tay)
                            break

            frame_idx += 1

        cap.release()
        total_images_all_videos += saved_count
        print(f"   ‚úÖ Xong video {video_name}. K·∫øt qu·∫£: {saved_count} ·∫£nh (Target: {TARGET_COUNT_PER_VIDEO})")

    cv2.destroyAllWindows()
    print(f"\nüéâ T·ªîNG K·∫æT: ƒê√£ t·∫°o ra {total_images_all_videos} ·∫£nh chu·∫©n 224x224.")


if __name__ == "__main__":
    main()